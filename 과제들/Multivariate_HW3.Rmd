---
title: "Multivariate_HW3"
author: "김민국"
date: '2019_11_11 '
header-includes:
  - \usepackage[hangul]{kotex}
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#### Problem 3

##### (a)
```{r echo=T, eval=TRUE}
data3 <- read.csv('pendigit3.txt', sep = ",", header = F) #data 불러오기
a <- data3[1,]
a1 <- unlist(c(a[1],a[3],a[5],a[7],a[9],a[11],a[13],a[15]))
a2 <- unlist(c(a[2],a[4],a[6],a[8],a[10],a[12],a[14],a[16]))
plot(a1,a2)
lines(a1,a2)  
```
-> pendigit3.txt 파일을 불러와서 첫번째 값의 plot을 그린 후 plot의 모양이 3과 유사함을 볼 수 있다.  

##### (b)
```{r echo=T, eval=TRUE}
data3_1 <- data3[,1:16] # 17번째 열 제거
pri_data3 <- princomp(data3_1)# pca 진행
loading <- pri_data3$loadings
lamda <- (pri_data3$sdev)^2
score <- pri_data3$scores
pairs(score)
```
-> 불러온 데이터의 17번째 열을 제거해준 새로운 data를 만들어준다.  
-> 그후 principal component analysis를 진행해주었다.  
-> pair 함수를 통해 principal components들의 scatterplot matrix를 그려주었다.  

```{r echo=T, eval=TRUE}
plot(lamda, main = "scree", xlab = "component", ylab = "lamda")
lines(lamda) 
```
-> pca를 한 후 scree plot을 그려주었다.  
-> cumulative scree plot은 (d)번에서 필요하기 때문에 그 때 그려주겠다.  

##### (c)
```{r echo=T, eval=TRUE}
par(mfrow = c(2,2))
for (i in 1:4){
  qqnorm(score[,i],main = paste("QQplot",i,"th","score") )
  qqline(score[,i], distribution = qnorm)
}
```
-> PC1에서 PC4까지 score들의 qqplot을 그려보았다.  

```{r echo=T, eval=TRUE}
par(mfrow = c(2,2))
for (i in 5:8){
  qqnorm(score[,i],main = paste("QQplot",i,"th","score") )
  qqline(score[,i], distribution = qnorm)
}
```
-> PC5에서 PC8까지 score들의 qqplot을 그려보았다.  

```{r echo=T, eval=TRUE}
par(mfrow = c(2,2))
for (i in 9:12){
  qqnorm(score[,i],main = paste("QQplot",i,"th","score") )
  qqline(score[,i], distribution = qnorm)
}
```
-> PC9에서 PC12까지 score들의 qqplot을 그려보았다.  

```{r echo=T, eval=TRUE}
par(mfrow = c(2,2))
for (i in 13:16){
  qqnorm(score[,i],main = paste("QQplot",i,"th","score") )
  qqline(score[,i], distribution = qnorm)
}
```
-> PC13에서 PC16까지 score들의 qqplot을 그려보았다.  
-> 16개의 PC에 대해 모두 qqplot을 보았을 때 직선의 경향을 따름을 볼 수 있다.  
-> 즉 이는 16개의 PC가 normal ditribution을 따르고 있음을 의미한다.  
-> PC들은 x들의 선형결함이다.  
-> 따라서 x들, 즉 data는 MVN distribution을 따른다고 할 수 있다.  

##### (d)
```{r echo=T, eval=TRUE}
plot(cumsum(lamda)*100/sum(lamda),main = "cumscree", xlab = "compoent", ylab = "cumulative percent")
lines(cumsum(lamda)*100/sum(lamda))
abline(h = 90)
summary(pri_data3)
```
-> cumulative scree plot과 PCA결과의 summary를 확인해보자.  
-> cumulative scree에 90%가 되는 직선을 그어주었을 때 90%를 넘기는 변수의 개수는 7개임을 확인할 수 있다.  
-> 이는 summary의 결과에서도 확인할 수 있다.  
-> 반드시 90%가 넘어야한다는 기준이면 7개를 사용해야 하지만 변수의 개수가 적은게 유리하면 6개도 상관없다.  

##### (e)
```{r echo=T, eval=TRUE}
data3_2 <- apply(data3_1,2,mean) #x의 평균 즉 x_bar 값이 된다.
```
-> 일단 data의 열의 평균값을 계산해주었다.  
-> 4개의 PC를 이용하되 각 PC만 이용한다는 것은 평균에서 각 PC 방향으로 떨어진 정도를 봐야한다.  
-> 이때 이용하는 식은 x_bar +- s * sqrt(lamda(i)) * loading(i) 이다.  
-> s는 -2, -1, 0, 1, 2 의 상수 값이며 sqrt(lamda)와 곱해줌으로 써 PC(i)의 특정 분산만큼 떨어진 정도를 의미한다.  
-> loading(i)를 곱해줌으로써 특정 분산값에서 멀어지되 PC(i)의 방향으로 움직이는 것을 의미하게 된다. 

```{r echo=T, eval=TRUE}
par(mfrow = c(1,5))
for(i in 1:5){
  x <- data3_2 + (-2 + (i-1)*1) * sqrt(lamda[1]) * loading[,1]
  a1 <- unlist(c(x[1],x[3],x[5],x[7],x[9],x[11],x[13],x[15]))
  a2 <- unlist(c(x[2],x[4],x[6],x[8],x[10],x[12],x[14],x[16]))
  plot(a1,a2)
  lines(a1,a2)
}
```
-> 평균에서 PC1방향으로 -2sigam , -sigma, 0, sigma, 2sigma 만큼 떨어진 경우의 그림을 그려준 것이다.  

```{r echo=T, eval=TRUE}
par(mfrow = c(1,5))
for(i in 1:5){
  x <- data3_2 + (-2 + (i-1)*1) * sqrt(lamda[2]) * loading[,2]
  a1 <- unlist(c(x[1],x[3],x[5],x[7],x[9],x[11],x[13],x[15]))
  a2 <- unlist(c(x[2],x[4],x[6],x[8],x[10],x[12],x[14],x[16]))
  plot(a1,a2)
  lines(a1,a2)
}
```
-> 평균에서 PC2방향으로 -2sigam , -sigma, 0, sigma, 2sigma 만큼 떨어진 경우의 그림을 그려준 것이다.  

```{r echo=T, eval=TRUE}
par(mfrow = c(1,5))
for(i in 1:5){
  x <- data3_2 + (-2 + (i-1)*1) * sqrt(lamda[3]) * loading[,3]
  a1 <- unlist(c(x[1],x[3],x[5],x[7],x[9],x[11],x[13],x[15]))
  a2 <- unlist(c(x[2],x[4],x[6],x[8],x[10],x[12],x[14],x[16]))
  plot(a1,a2)
  lines(a1,a2)
}
```
-> 평균에서 PC3방향으로 -2sigam , -sigma, 0, sigma, 2sigma 만큼 떨어진 경우의 그림을 그려준 것이다.  

```{r echo=T, eval=TRUE}
par(mfrow = c(1,5))
for(i in 1:5){
  x <- data3_2 + (-2 + (i-1)*1) * sqrt(lamda[4]) * loading[,4]
  a1 <- unlist(c(x[1],x[3],x[5],x[7],x[9],x[11],x[13],x[15]))
  a2 <- unlist(c(x[2],x[4],x[6],x[8],x[10],x[12],x[14],x[16]))
  plot(a1,a2)
  lines(a1,a2)
}
```
-> 평균에서 PC4방향으로 -2sigam , -sigma, 0, sigma, 2sigma 만큼 떨어진 경우의 그림을 그려준 것이다.  

##### (f)
```{r echo=T, eval=TRUE}
data8 <- read.csv('pendigit8.txt', sep = ",", header = F) # pendigit8.txt를 불러온다.
data <- rbind(data3,data8)  # 두개의 데이터를 합쳐준다.                
data_1 <- data[,1:16] # 마지막 열을 제거
pri_data <- princomp(data_1) # PCA
loading1 <- pri_data$loadings
lamda1 <- (pri_data$sdev)^2
score1 <- pri_data$scores
par(mfrow = c(1,1))
pairs(score1, col = c(rep("blue",1105),rep("red",1105)))
```
-> pendigit8.txt 파일을 불러와서 pendigit3.txt 파일 뒤에 붙여주었다.  
-> PCA를 진행한 후 PC들의 scatterplot matrix를 그려주었다.  

```{r echo=T, eval=TRUE}
par(mfrow = c(1,2))
plot(lamda1, main = "scree", xlab = "component", ylab = "lamda")
lines(lamda1)
plot(cumsum(lamda1)*100/sum(lamda1),main = "cumscree", xlab = "compoent", ylab = "cumulative percent")
lines(cumsum(lamda1)*100/sum(lamda1))
abline(h=90)
```
-> 그 후 scree plot과 cumulative scree plot을 그려주었다.  
-> cumulative scree plot을 보았을 때 90% 이상 설명해주는 변수의 개수는 5개임을 알 수 있다.  
-> 따라서 5개의 PC들을 가지고 분류가 잘 이루어졌는지 확인하고자 한다.  

```{r echo=T, eval=TRUE}
par(mfrow = c(1,1))
pairs(score1[,1:5], col = c(rep("blue",1105),rep("red",1105)))
```
-> 파란점은 digit3을 붉은점은 digit8을 의미한다.  
-> PC scatterplot matrix에서 PC1를 나타내는 1행을 보았을 때 둘의 분류가 어느정도 잘 이루어지는 것을 확인할 수 있다.  
